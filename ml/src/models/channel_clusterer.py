"""
Channel Clusterer â€” K-Means clustering trÃªn 42 kÃªnh.
DÃ¹ng Ä‘á»ƒ assign cluster khi cÃ³ kÃªnh má»›i vÃ  táº¡o prior probability.
"""
from __future__ import annotations

import logging
import pickle
from pathlib import Path
from typing import Optional

import numpy as np
import pandas as pd
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn.preprocessing import StandardScaler

logger = logging.getLogger(__name__)

TRAINED_MODELS_DIR = Path(__file__).parent.parent.parent / "trained_models"
CLUSTERER_PATH = TRAINED_MODELS_DIR / "channel_clusterer.pkl"

CLUSTER_NAMES = {
    0: "Tier 0 â€” Mega Channels",
    1: "Tier 1 â€” Large Channels",
    2: "Tier 2 â€” Growing Channels",
    3: "Tier 3 â€” Niche Channels",
    4: "Tier 4 â€” Small Channels",
}


class ChannelClusterer:
    """
    K-Means clustering cho kÃªnh YouTube.

    Usage:
        clusterer = ChannelClusterer()
        clusterer.fit(channel_features_df)  # sau khi cÃ³ labels
        cluster_id, distance = clusterer.assign_cluster(new_channel_features)
        stats = clusterer.get_cluster_stats(cluster_id)
        ChannelClusterer.load() Ä‘á»ƒ load model Ä‘Ã£ train
    """

    CLUSTER_FEATURES = [
        "f9_sub_tier",          # log10(subscribers)
        "f6_avg_views",         # avg views per video â†’ log transform
        "f2_loyalty",           # like/view ratio
        "f3_depth",             # comment/view ratio
    ]

    def __init__(self, n_clusters: int = 4) -> None:
        self.n_clusters = n_clusters
        self._scaler = StandardScaler()
        self._kmeans: Optional[KMeans] = None
        self._cluster_stats: dict[int, dict] = {}
        self._is_fitted = False

    # â”€â”€ Fit â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def find_optimal_k(
        self,
        channel_features: pd.DataFrame,
        k_range: range = range(2, 9),
    ) -> int:
        """
        TÃ¬m k tá»‘i Æ°u báº±ng Elbow Method + Silhouette Score.

        Returns:
            Optimal k (int)
        """
        X = self._extract_cluster_features(channel_features)
        X_scaled = self._scaler.fit_transform(X)

        inertias = []
        silhouettes = []

        for k in k_range:
            km = KMeans(n_clusters=k, random_state=42, n_init=10)
            labels = km.fit_predict(X_scaled)
            inertias.append(km.inertia_)
            if k > 1:
                sil = silhouette_score(X_scaled, labels)
                silhouettes.append(sil)
            else:
                silhouettes.append(0.0)

        print(f"\n{'â”€'*50}")
        print(f"ðŸ“Š ELBOW METHOD + SILHOUETTE SCORE")
        print(f"{'â”€'*50}")
        for i, k in enumerate(k_range):
            sil = silhouettes[i]
            inert = inertias[i]
            bar = "â–ˆ" * int(sil * 40)
            print(f"  k={k}: inertia={inert:8.0f}, silhouette={sil:.3f} {bar}")

        # Chá»n k cÃ³ silhouette cao nháº¥t
        best_k_idx = int(np.argmax(silhouettes))
        best_k = list(k_range)[best_k_idx]
        print(f"\n  âœ… Optimal k = {best_k} (silhouette = {silhouettes[best_k_idx]:.3f})")
        print(f"{'â”€'*50}\n")
        return best_k

    def fit(
        self,
        channel_features: pd.DataFrame,
        labeled_df: Optional[pd.DataFrame] = None,
        auto_find_k: bool = True,
    ) -> "ChannelClusterer":
        """
        Fit K-Means trÃªn channel features.

        Args:
            channel_features: DataFrame tá»« ChannelFeatureEngineer.transform()
            labeled_df:       DataFrame vá»›i cá»™t is_viral_channel (Ä‘á»ƒ tÃ­nh viral rate per cluster)
            auto_find_k:      True â†’ tá»± tÃ¬m k tá»‘i Æ°u
        """
        X = self._extract_cluster_features(channel_features)

        if auto_find_k:
            k = self.find_optimal_k(channel_features, k_range=range(2, min(8, len(X))))
            self.n_clusters = k

        X_scaled = self._scaler.fit_transform(X)
        self._kmeans = KMeans(n_clusters=self.n_clusters, random_state=42, n_init=20)
        cluster_labels = self._kmeans.fit_predict(X_scaled)

        channel_features = channel_features.copy()
        channel_features["cluster_id"] = cluster_labels

        # Merge viral labels náº¿u cÃ³
        if labeled_df is not None and "is_viral_channel" in labeled_df.columns:
            label_col = labeled_df["is_viral_channel"].values
            channel_features["is_viral_channel"] = label_col

        # TÃ­nh cluster stats
        self._compute_cluster_stats(channel_features)
        self._is_fitted = True

        self._print_cluster_summary(channel_features)
        logger.info("ChannelClusterer fitted: k=%d", self.n_clusters)
        return self

    def _compute_cluster_stats(self, df: pd.DataFrame) -> None:
        # BÆ°á»›c 1: tÃ­nh stats thÃ´
        raw: dict[int, dict] = {}
        for cluster_id in range(self.n_clusters):
            mask = df["cluster_id"] == cluster_id
            subset = df[mask]
            stats: dict = {"count": int(mask.sum())}
            if "is_viral_channel" in subset.columns:
                stats["viral_rate"] = float(subset["is_viral_channel"].mean())
            else:
                stats["viral_rate"] = 0.5
            for feat in self.CLUSTER_FEATURES:
                if feat in subset.columns:
                    stats[f"median_{feat}"] = float(subset[feat].median())
            raw[cluster_id] = stats

        # BÆ°á»›c 2: Ä‘áº·t tÃªn Ä‘á»™ng theo median f9_sub_tier (subscribers)
        # Cluster cÃ³ sub tier cao nháº¥t = Mega, tiáº¿p theo Large, Growing, Nicheâ€¦
        TIER_NAMES = [
            "Mega Channels (100M+ sub)",
            "Large Channels (1Mâ€“100M sub)",
            "Growing Channels (100Kâ€“1M sub)",
            "Niche Channels (<100K sub)",
            "Micro Channels",
        ]
        sorted_ids = sorted(
            raw.keys(),
            key=lambda cid: raw[cid].get("median_f9_sub_tier", 0),
            reverse=True,  # tier cao nháº¥t = sub nhiá»u nháº¥t
        )
        for rank, cid in enumerate(sorted_ids):
            raw[cid]["name"] = TIER_NAMES[min(rank, len(TIER_NAMES) - 1)]
            raw[cid]["tier_rank"] = rank  # 0 = lá»›n nháº¥t

        self._cluster_stats = raw

    def _print_cluster_summary(self, df: pd.DataFrame) -> None:
        print(f"\n{'â”€'*60}")
        print(f"ðŸ“Š CHANNEL CLUSTERING SUMMARY (k={self.n_clusters})")
        print(f"{'â”€'*60}")
        for cid, stats in sorted(self._cluster_stats.items()):
            viral_rate_str = f"{stats['viral_rate']*100:.1f}%" if "viral_rate" in stats else "â€”"
            print(f"  Cluster {cid} | {stats['count']:3d} kÃªnh | viral rate: {viral_rate_str}")
            print(f"    {stats['name']}")
        print(f"{'â”€'*60}\n")

    # â”€â”€ Predict â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def assign_cluster(
        self, features: pd.DataFrame
    ) -> tuple[int, float, dict]:
        """
        Assign cluster cho kÃªnh má»›i.

        Args:
            features: DataFrame 1 dÃ²ng tá»« ChannelFeatureEngineer

        Returns:
            (cluster_id, distance_to_centroid, cluster_stats)
        """
        self._check_fitted()
        X = self._extract_cluster_features(features)
        X_scaled = self._scaler.transform(X)
        cluster_id = int(self._kmeans.predict(X_scaled)[0])

        # TÃ­nh khoáº£ng cÃ¡ch tá»›i centroid
        centroid = self._kmeans.cluster_centers_[cluster_id]
        distance = float(np.linalg.norm(X_scaled[0] - centroid))

        return cluster_id, distance, self._cluster_stats.get(cluster_id, {})

    # â”€â”€ Save / Load â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def save(self, path: Optional[Path] = None) -> Path:
        TRAINED_MODELS_DIR.mkdir(parents=True, exist_ok=True)
        save_path = path or CLUSTERER_PATH
        with open(save_path, "wb") as f:
            pickle.dump(self, f)
        logger.info("âœ… Clusterer Ä‘Ã£ lÆ°u: %s", save_path)
        return save_path

    @classmethod
    def load(cls, path: Optional[Path] = None) -> "ChannelClusterer":
        load_path = path or CLUSTERER_PATH
        with open(load_path, "rb") as f:
            obj = pickle.load(f)
        logger.info("âœ… Clusterer Ä‘Ã£ táº£i: %s", load_path)
        return obj

    # â”€â”€ Helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _extract_cluster_features(self, df: pd.DataFrame) -> np.ndarray:
        available = [f for f in self.CLUSTER_FEATURES if f in df.columns]
        if not available:
            raise ValueError(f"KhÃ´ng cÃ³ feature nÃ o phÃ¹ há»£p. Cáº§n: {self.CLUSTER_FEATURES}")
        X = df[available].fillna(0).values.copy()  # copy Ä‘á»ƒ trÃ¡nh read-only array

        # Log transform avg_views
        avg_views_idx = available.index("f6_avg_views") if "f6_avg_views" in available else None
        if avg_views_idx is not None:
            X[:, avg_views_idx] = np.log1p(X[:, avg_views_idx])
        return X

    def _check_fitted(self) -> None:
        if not self._is_fitted:
            raise RuntimeError("Clusterer chÆ°a Ä‘Æ°á»£c fit. Gá»i fit() hoáº·c load() trÆ°á»›c.")

    def get_cluster_name(self, cluster_id: int) -> str:
        return self._cluster_stats.get(cluster_id, {}).get("name", f"Cluster {cluster_id}")

    def get_cluster_viral_rate(self, cluster_id: int) -> float:
        return self._cluster_stats.get(cluster_id, {}).get("viral_rate", 0.5)
